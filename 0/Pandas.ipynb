{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Dataframe Exploration - Restaurant Inspection\n",
    "\n",
    "Modified from an IPython Notebook created by Jonathan Dinu [here](http://nbviewer.jupyter.org/github/Jay-Oh-eN/happy-healthy-hungry/blob/master/h3.ipynb)\n",
    "\n",
    "Now, let's use dataframes to explore a dataset containing inspection records for San Francisco restaurants. We'll be using this publicly available [dataset](http://www.sfdph.org/dph/EH/Food/score/default.asp) from the Department of Public health.  We will explore this data to map the cleanliness of the city, and get a better perspective on the relative meaning of these scores by looking at statistics of the data. This notebook can be downloaded (with associated data) from its [repo](https://github.com/Jay-Oh-eN/happy-healthy-hungry)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Problem___\n",
    "\n",
    "The first step of the data analysis process is to define the problem we want to address.  To do so let us review what we have set out to accomplish and begin exploring questions we want answered.\n",
    "\n",
    "> ### How clean are SF restaurants?\n",
    "\n",
    "It is often best to arrive at a simple yet illuminating question to give you direction.  Of course there are a number of sub-questions we may have that relate to our over arching problem, we can address these when we determine our goals for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"goals\"></a>\n",
    "## ___Determine Goal___\n",
    "\n",
    "Now that we have a problem we hope to solve, let us begin to quantify our analysis.  Since our _Problem Statement_ is often qualitative and broad, we can ask further questions to better define what we hope to achieve.\n",
    "\n",
    "> How does an individual restaurants' score compare to the whole/aggregate of SF?\n",
    "\n",
    "> Are SF's inspections better or worse than other cities?\n",
    "\n",
    "> If a restaurant has not yet been inspected, can we approximate/predict what score it will receive? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Explore and Transform___\n",
    "\n",
    "To get a better understanding of the data, we can start to begin examining it statistically to get a macrosopic look at its distribution.  This part of our tutorial will use much of the powerful built in functionality of [NumPy](http://www.numpy.org/), [SciPy](http://www.scipy.org/), [matplotlib](http://matplotlib.org/), and [pandas](http://pandas.pydata.org/).  If you want to get more experience with these, there are great [resources](http://fperez.org/py4science/starter_kit.html) and [tutorials](http://www.rexx.com/~dkuhlman/scipy_course_01.html) covering these libraries in much more [depth](http://scipy-lectures.github.io/) than I will here.  I highly recommend taking a look at these if this analysis interests you even in the least bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import pylab to provide scientific Python libraries (NumPy, SciPy, Matplotlib)\n",
    "%pylab --no-import-all\n",
    "#import pylab as pl\n",
    "# import the Image display module\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the data into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas library which provides an R like environment for python.\n",
    "# if you do not have it installed: sudo easy_install pandas.\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "# store relevant file paths in variables since we may use them frequently\n",
    "businesses = 'businesses.csv'\n",
    "inspections = 'inspections.csv'\n",
    "\n",
    "# load each file into a Pandas DataFrame, pandas automatically converts the first line into a header for the columns\n",
    "df_business = pd.read_csv(businesses)\n",
    "df_inspection = pd.read_csv(inspections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can inspect the first 10 rows of the DataFrame to ensure that the data is loaded properly and get an idea of the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_inspection.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can 'join' DataFrames just as we would database tables pandas uses a left-outer join by default, meaning that all \n",
    "the records from the businesses will be present even if there\n",
    "is not a corresponding row in the inspections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the two DataFrames on the 'business_id' column\n",
    "big_table = df_business.merge(df_inspection, on='business_id')\n",
    "\n",
    "# the joined DataFrame columns: frame1 columns + frame2 columns\n",
    "# in our case it is the concatenation of df_business and df_inspection columns\n",
    "print 'Business:\\t' + str(df_business.columns) + '\\n'\n",
    "print 'Inspection:\\t' + str(df_inspection.columns) + '\\n'\n",
    "print 'Big Table:\\t' + str(big_table.columns)\n",
    "\n",
    "# allows for row and column indexing succinctly\n",
    "big_table.iloc[:10, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now that we have our joined data, we can start exploring it__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by grouping our data by business in order to find its most recent score for the inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_business = big_table.groupby('business_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a new DataFrame by applying a function to the old DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a funtion that takes a DataFrame and returns the row with the newest date\n",
    "def most_recent(df, column='date'):\n",
    "    return df.sort_values(by=column)[-1:]\n",
    "    \n",
    "# input to most_recent is the DataFrame of each group, in this case \n",
    "# all of the rows and columns for each business (grouped on business_id). \n",
    "most_recent_inspection_results = grouped_business.apply(most_recent)\n",
    " \n",
    "# We applied the most_recent function to extract the row\n",
    "# of the DataFrame with the most recent inspection.\n",
    "most_recent_inspection_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important aspect of the exploration process is removing bad data. Here, we filter out records without lat/long for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = most_recent_inspection_results\n",
    "\n",
    "zero_filtered = r[(r['latitude'] != 0) & (r['latitude'] != 0)]\n",
    "\n",
    "filtered = zero_filtered.dropna(subset=['latitude', 'longitude'])[['business_id','name', 'address', 'Score', 'date', 'latitude', 'longitude']]\n",
    "\n",
    "filtered.to_csv('geolocated_rest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-Apply-Combine\n",
    "A visual representation of how group-by, aggregate, and apply semantics work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We can bin the restaurants by scores to understand the distribution of inspections better.  Here we create a histogram to understand the distribution of scores better__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "# create a matplotlib figure with size [15,7]\n",
    "figure(figsize=[15,7])\n",
    "\n",
    "# pandas built-in histogram function automatically distributes and counts bin values \n",
    "h = most_recent_inspection_results['Score'].hist(bins=100)\n",
    "\n",
    "# create x-axis ticks of even numbers 0-100\n",
    "xticks(np.arange(40, 100, 2))\n",
    "\n",
    "# add a title to the current figure, our histogram\n",
    "h.set_title(\"Histogram of Inspection Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a basic idea of the distribution, let us look at some more interesting statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores =  most_recent_inspection_results['Score']\n",
    "mean = scores.mean()\n",
    "median = scores.median()\n",
    "\n",
    "# compute descriptive summary statistics of the inspection scores\n",
    "summary = scores.describe()\n",
    "\n",
    "mode = sp.stats.mode(scores)\n",
    "skew = scores.skew()\n",
    "\n",
    "# compute quantiles\n",
    "ninety = scores.quantile(0.9)\n",
    "eighty = scores.quantile(0.8)\n",
    "seventy = scores.quantile(0.7)\n",
    "sixty = scores.quantile(0.6)\n",
    "\n",
    "print \"Skew: \" + str(skew)\n",
    "print \"90%: \" + str(ninety)\n",
    "print \"80%: \" + str(eighty)\n",
    "print \"70%: \" + str(seventy)\n",
    "print \"60%: \" + str(sixty)\n",
    "print summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Propose Solutions___\n",
    "\n",
    "Since we have explored our data and have a better idea of its nature, we can begin to devise a plan to answer our questions. This is usually the most iterative part of the entire process: as we learn more about our data we modify our approach, and as modify our solutions we must re-examine our data.\n",
    "\n",
    "#### Goals:\n",
    "> How does an individual restaurants' score compare to the whole/aggregate of SF?\n",
    "\n",
    "> Are SF's inspections better or worse than other cities?\n",
    "\n",
    "> If a restaurant has not yet been inspected, can we approximate/predict what score it will receive? \n",
    "\n",
    "#### Solutions:\n",
    "> Collect summary statistics (mean, median, standard deviation, etc.) about distribution of scores.\n",
    "\n",
    "> Acquire data on inspection scores for other cities, compare distribution of cities.\n",
    "\n",
    "> Perform a linear regression on historic data on past inspections combined with scores from other 'similar' restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Collect Metrics___\n",
    "\n",
    "This is the step where derivative values are often calculated, including __summary statistics__, __transformations__ on the data, and __correlations__.  There also is a bit of traditional __data mining__ involved as most machine learning occurs in the solutions and metrics stages (in our formulation).  We could even go so far as to say that the results of predictive models are simply additional metrics: the __probability__ of defaulting on a loan, the __cluster__ a new product belongs in, or the __score__ of a restaurant that hasn't been inspected yet.\n",
    "    \n",
    "___The purpose of this part of the process is to calculate the information you need to begin evaluating and testing you solutions and hypotheses.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a mapping from score ranges to descriptions, we want to assign a discription to each business in our grouped DataFrame. We will use create description bins using the description ranges, then use a built-in Pandas function to assign each business to a bin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first we need to discretize the numerical values, this can be \n",
    "# thought of as converting a continuous variable into a categorical one.\n",
    "descriptions = ['Poor', 'Needs Improvement', 'Adequate', 'Good']\n",
    "bins = [-1, 70, 85, 90, 100]\n",
    "\n",
    "# copy the scores from our grouped DataFrame, DataFrames manipulate\n",
    "# in place if we do not explicitly copy them.\n",
    "scores = most_recent_inspection_results['Score'].copy()\n",
    "score_transform = most_recent_inspection_results.copy()\n",
    "\n",
    "# built-in pandas function which assigns each data point in \n",
    "# 'scores' to an interval in 'bins' with labels of 'descriptions'\n",
    "discretized_scores = pd.cut(scores, bins ,labels=descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply these transformations to the old DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tranform the original DataFrame's \"Score\" column with the new descriptions\n",
    "score_transform['Score'] = discretized_scores\n",
    "\n",
    "score_transform[['name', 'date','Score']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__By quantizing the scores of the restaurant inspections, we can get a better qualitative insight into the ratings.  Let us compare this new distribution of quantized scores to the raw numeric values.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Evaluate___\n",
    "\n",
    "With the metrics we need properly calculated, it is time to draw some conclusions from our analyses.  We need to evaluate whether the result we have arrived at:\n",
    "    \n",
    "* Answers our original question to an acceptable level of confidence.\n",
    "* Has allowed us to achieve our goals? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a histogram of the discretized scores to visualize where the restaurant scores fall within our description bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a figure with 2 subplots\n",
    "fig = figure(figsize=[30,7])\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "# count each occurance of descriptions in the 'Score' column,\n",
    "# and reverse this result so 'Poor' is left most and 'Good' right most\n",
    "counts = score_transform['Score'].value_counts()[::-1]\n",
    "plt = counts.plot(kind='bar', ax=ax2)\n",
    "\n",
    "# decorate the plot and axis with text\n",
    "ax2.set_title(\"Restaurant Inspections (%i total)\" % sum(counts))\n",
    "ax2.set_ylabel(\"Counts\")\n",
    "ax2.set_xlabel(\"Description\")\n",
    "\n",
    "# let us add some labels to each bar\n",
    "for x, y in enumerate(counts):\n",
    "    plt.text(x + 0.5, y + 200, '%.f' % y, ha='left', va= 'top')\n",
    "    \n",
    "# plot the original raw scores (same graph as earlier)\n",
    "most_recent_inspection_results['Score'].hist(bins=100, ax= ax1)\n",
    "# create x-axis ticks of even numbers 0-100\n",
    "ax1.set_xticks(np.arange(40, 100, 2))\n",
    "\n",
    "# add a title to the current figure, our histogram\n",
    "ax1.set_title(\"Histogram of Inspection Scores\")\n",
    "ax1.set_ylabel(\"Counts\")\n",
    "ax1.set_xlabel(\"Score\")\n",
    "\n",
    "savefig('histograms.png', bbox_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a majority of restaurants are __adequate__ or __good__, according to the quantiles only __25%__ have scores less than __88__.  While the histogram of the numeric scores gives us a more granular look at the data, it can be quite difficult to derive value from it.  Is an __86__ a filthy/unhealthy restaurant or did it simply forget a few nuanced inspection rules?  The Score Legend provides us a mapping from a raw score to a meaningful value, similar to the scaling of standardized test raw scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not satisfied with our evaluation, we need to iterate on our approach:\n",
    "    \n",
    "* Do I need more/better data?\n",
    "* Do I need to try a different proposed solution?\n",
    "* Do I need to calculate different metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the histogram once again, this time marking the quantiles to provide a more meaningful representation of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a matplotlib figure with size [15,7]\n",
    "figure(figsize=[15,7])\n",
    "\n",
    "# pandas built-in histogram function automatically distributes and counts bin values \n",
    "h = most_recent_inspection_results['Score'].hist(bins=100)\n",
    "\n",
    "# summary statistics vertical lines\n",
    "axvline(x=mean,color='red',ls='solid', lw=\"3\", label=\"mean\")\n",
    "axvline(x=median,color='green',ls='solid', lw=\"3\", label=\"median\")\n",
    "axvline(x=mode[0][0],color='orange',ls='solid', lw=\"3\", label=\"mode\")\n",
    "\n",
    "# 25th quantile\n",
    "axvline(x=summary['25%'],color='maroon',ls='dashed', lw=\"3\", label=\"25th\")\n",
    "axvspan(40, summary['25%'], facecolor=\"maroon\", alpha=0.3)\n",
    "\n",
    "# 75th quantile\n",
    "axvline(x=summary['75%'],color='black',ls='dashed', lw=\"3\", label=\"75th\")\n",
    "axvspan(40, summary['75%'], facecolor=\"yellow\", alpha=0.3 )\n",
    "\n",
    "# create x-axis ticks of even numbers 0-100\n",
    "xticks(np.arange(40, 104, 2))\n",
    "\n",
    "# add legend to graph\n",
    "legend(loc=2)\n",
    "\n",
    "# add a title to the current figure, our histogram\n",
    "h.set_title(\"Histogram of Inspection Scores with Quantiles\")\n",
    "\n",
    "savefig('quantiles.png', bbox_inches=0, transparent=True)\n",
    "\n",
    "print summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Iterate___\n",
    "\n",
    "Now that we have a general idea of the distribution of these scores, let us see if we can find any correlation between score ranges and health violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re as re\n",
    "import collections as c\n",
    "import pprint as pp\n",
    "\n",
    "# first let us form a 'big table' by joining the violations to the most recent inspection scores\n",
    "file=\"violations_plus.csv\"\n",
    "\n",
    "df_violations = pd.read_csv(file)\n",
    "\n",
    "violation_table = most_recent_inspection_results.merge(df_violations, on=['business_id','date'])\n",
    "violation_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a histogram for the violations data to see how the violations are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=[18,7])\n",
    "\n",
    "violation_hist = violation_table['description'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also be curious to see what violations a restaurant can have and still get a perfect score, so we'll filter the violation table for perfect scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=[18,7])\n",
    "\n",
    "perfect_scores = violation_table[violation_table['Score'] == 100]\n",
    "perfect_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll plot a new violation histogram based on the filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "violation_hist = perfect_scores['description'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at how health violations are distributed across the different score description bins. We'll use the same discretizing process used earlier to create the score descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let us bin health violations using the cities quantizations\n",
    "descriptions = ['Poor', 'Needs Improvement', 'Adequate', 'Good']\n",
    "bins = [-1, 70, 85, 90, 100]\n",
    "\n",
    "# copy the scores from our grouped DataFrame, DataFrames manipulate\n",
    "# in place if we do not explicitly copy them.\n",
    "scores = violation_table['Score'].copy()\n",
    "violation_transform = violation_table.copy()\n",
    "\n",
    "# built-in pandas funcion which assigns each data point in \n",
    "# 'scores' to an interval in 'bins' with labels of 'descriptions'\n",
    "discretized_scores = pd.cut(scores, bins ,labels=descriptions)\n",
    "violation_transform[\"Scores\"] = discretized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = violation_transform.groupby('Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the most common violations for each group by applying a function that counts and normalizes the offense types across the description groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a funtion that takes a DataFrame and returns the top violations\n",
    "def common_offenses(df):\n",
    "    return pd.DataFrame(df['description'].value_counts(normalize=True) * 100).head(10)\n",
    "\n",
    "top_offenses = grouped.apply(common_offenses)\n",
    "top_offenses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
